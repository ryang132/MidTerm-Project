{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNPI7/DBsxiF2/zHw+yk8JH",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ryang132/MidTerm-Project/blob/main/RobertYang_Assignment2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Download the Dataset provided and upload to the drive\n"
      ],
      "metadata": {
        "id": "XIRl60mwK01_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#unzip the dataset\n",
        "!unzip -q tiny_Data.zip -d Data"
      ],
      "metadata": {
        "id": "ck-5nTQ1fb3c"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "x16YKJ2Ob5Ec",
        "outputId": "5a56f0bc-3fcf-42fd-d062-407e96628343"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "95/95 [==============================] - 636s 7s/step - loss: 0.6659 - accuracy: 1.0000 - val_loss: 0.6426 - val_accuracy: 1.0000\n",
            "Epoch 2/10\n",
            "95/95 [==============================] - 628s 7s/step - loss: 0.6209 - accuracy: 1.0000 - val_loss: 0.5989 - val_accuracy: 1.0000\n",
            "Epoch 3/10\n",
            "95/95 [==============================] - 641s 7s/step - loss: 0.5782 - accuracy: 1.0000 - val_loss: 0.5574 - val_accuracy: 1.0000\n",
            "Epoch 4/10\n",
            "95/95 [==============================] - 629s 7s/step - loss: 0.5378 - accuracy: 1.0000 - val_loss: 0.5181 - val_accuracy: 1.0000\n",
            "Epoch 5/10\n",
            "95/95 [==============================] - 634s 7s/step - loss: 0.4996 - accuracy: 1.0000 - val_loss: 0.4810 - val_accuracy: 1.0000\n",
            "Epoch 6/10\n",
            "95/95 [==============================] - 628s 7s/step - loss: 0.4636 - accuracy: 1.0000 - val_loss: 0.4460 - val_accuracy: 1.0000\n",
            "Epoch 7/10\n",
            "95/95 [==============================] - 626s 7s/step - loss: 0.4295 - accuracy: 1.0000 - val_loss: 0.4130 - val_accuracy: 1.0000\n",
            "Epoch 8/10\n",
            "95/95 [==============================] - 622s 7s/step - loss: 0.3976 - accuracy: 1.0000 - val_loss: 0.3820 - val_accuracy: 1.0000\n",
            "Epoch 9/10\n",
            "95/95 [==============================] - 613s 6s/step - loss: 0.3675 - accuracy: 1.0000 - val_loss: 0.3530 - val_accuracy: 1.0000\n",
            "Epoch 10/10\n",
            "95/95 [==============================] - 618s 7s/step - loss: 0.3394 - accuracy: 1.0000 - val_loss: 0.3259 - val_accuracy: 1.0000\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from PIL import Image\n",
        "import os\n",
        "import cv2\n",
        "from tensorflow.keras.utils import Sequence\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "class DataGenerator(Sequence):\n",
        "    def __init__(self, directory, batch_size, image_size, augment=False):\n",
        "        self.directory = directory\n",
        "        self.batch_size = batch_size\n",
        "        self.image_size = image_size\n",
        "        self.augment = augment\n",
        "        self.classes = sorted(os.listdir(directory))\n",
        "        self.num_classes = len(self.classes)\n",
        "        self.class_indices = dict(zip(self.classes, range(self.num_classes)))\n",
        "        self.samples = []\n",
        "        for class_name in self.classes:\n",
        "            class_dir = os.path.join(directory, class_name)\n",
        "            for filename in os.listdir('/content/Data/Data_Small/train'):\n",
        "                self.samples.append((os.path.join(class_dir, filename), class_name))\n",
        "        self.num_samples = len(self.samples)\n",
        "\n",
        "    def __len__(self):\n",
        "        return int(np.ceil(self.num_samples / float(self.batch_size)))\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        batch_samples = self.samples[index*self.batch_size:(index+1)*self.batch_size]\n",
        "        X = np.zeros((len(batch_samples), *self.image_size, 3), dtype=np.float32)\n",
        "        y = np.zeros((len(batch_samples), len(self.classes)), dtype=np.float32)\n",
        "        for i, (filename, class_name) in enumerate(batch_samples):\n",
        "            try:\n",
        "                img = cv2.imread(filename)\n",
        "                if img is None:\n",
        "                    continue  # Skip over images that cannot be loaded\n",
        "                img = cv2.resize(img, self.image_size)\n",
        "                img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
        "                img = np.array(img) / 255.0\n",
        "                X[i] = img\n",
        "                y[i, self.class_indices[class_name]] = 1\n",
        "            except Exception as e:\n",
        "                print(f\"Error loading image {filename}: {e}\")\n",
        "        return X, y\n",
        "\n",
        "    def _augment_image(self, img):\n",
        "        # Create an instance of the image data generator\n",
        "        datagen = ImageDataGenerator(rotation_range=20,\n",
        "                                     width_shift_range=0.1,\n",
        "                                     height_shift_range=0.1,\n",
        "                                     shear_range=0.2,\n",
        "                                     zoom_range=0.2,\n",
        "                                     horizontal_flip=True,\n",
        "                                     fill_mode='nearest')\n",
        "        # Add a batch dimension to the image and apply augmentation\n",
        "        img = np.expand_dims(img, axis=0)\n",
        "        img = datagen.flow(img, batch_size=1)[0][0]\n",
        "        # Remove the batch dimension from the augmented image\n",
        "        img = np.squeeze(img, axis=0)\n",
        "        return img\n",
        "\n",
        "\n",
        "# Define data directories\n",
        "train_dir = '/content/Data/Data_Small/train/DME'\n",
        "val_dir = '/content/Data/Data_Small/train/DRUSEN'\n",
        "\n",
        "# Define model parameters\n",
        "img_width, img_height = 256, 256\n",
        "batch_size = 32\n",
        "epochs = 10\n",
        "\n",
        "# Define data generators\n",
        "train_generator = DataGenerator(train_dir, batch_size, image_size=(img_width, img_height), augment=True)\n",
        "val_generator = DataGenerator(val_dir, batch_size, image_size=(img_width, img_height))\n",
        "\n",
        "# Define the model\n",
        "model = tf.keras.models.Sequential([\n",
        "    tf.keras.layers.Conv2D(32, (3,3), activation='relu', input_shape=(img_width, img_height, 3)),\n",
        "    tf.keras.layers.MaxPooling2D((2,2)),\n",
        "    tf.keras.layers.Conv2D(64, (3,3), activation='relu'),\n",
        "    tf.keras.layers.MaxPooling2D((2,2)),\n",
        "    tf.keras.layers.Conv2D(128, (3,3), activation='relu'),\n",
        "    tf.keras.layers.MaxPooling2D((2,2)),\n",
        "    tf.keras.layers.Conv2D(128, (3,3), activation='relu'),\n",
        "    tf.keras.layers.MaxPooling2D((2,2)),\n",
        "\n",
        "    tf.keras.layers.Flatten(),\n",
        "    tf.keras.layers.Dense(512, activation='relu'),\n",
        "    tf.keras.layers.Dense(1, activation='sigmoid')\n",
        "])\n",
        "\n",
        "# Compile the model\n",
        "model.compile(loss='binary_crossentropy',\n",
        "              optimizer=tf.keras.optimizers.RMSprop(),\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "\n",
        "\n",
        "# Train the model\n",
        "history = model.fit(train_generator, epochs=epochs, validation_data=val_generator)\n",
        "\n",
        "\n"
      ]
    }
  ]
}